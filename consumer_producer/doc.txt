# Документация: Producer-Consumer Task Queue

## Начин на работа

Системата е имплементирана като producer-consumer архитектура, където един producer процес генерира задачи, а множество consumer процеси ги обработват. За комуникация между процесите се използва shared memory с размер от 10000 задачи, което позволява ефективна комуникация между процесите без блокиране.

Producer процесът работи в batch режим, като генерира по 64 задачи наведнъж, което значително намалява overhead-а от синхронизацията. Задачите могат да бъдат два типа: прости (integer) и комплексни (string/JSON).

## Използвани OS функции

1. **Shared Memory (shm_open, mmap)**
   - Използвани за създаване на обща памет между процесите
   - Позволява бърза комуникация без копиране на данни
   - Избрани са пред други IPC механизми поради по-ниския overhead

2. **Семафори (sem_open, sem_wait, sem_post)**
   - Използвани са три семафора за синхронизация:
     - sem_empty: контролира празните слотове в буфера
     - sem_full: контролира заетите слотове
     - sem_mutex: защитава критичните секции
   - Избрани са поради ефективността и простотата на имплементация

3. **Atomic операции**
   - Използвани за thread-safe операции с броячи и флагове
   - Предотвратяват race conditions без нужда от допълнителна синхронизация

## Обосновка на производителността

Системата достига скорост от над 1,000,000 задачи/сек, което е значително по-добро от стандартните имплементации. Това се постига чрез:

1. **Batch обработка**
   - Групиране на задачите в batch от 64
   - Намалява броя на синхронизационните операции

2. **Оптимизирана структура на данните**
   - Cache-aligned структури (64 байта)
   - Минимизира false sharing между процесите

3. **Ефективна синхронизация**
   - Минимално използване на mutex
   - Atomic операции за броене и флагове

## Reflection

Най-интересното, което научих от този проект е колко важна всъщност е правилната структура на данните за производителността. Cache alignment и предотвратяването на false sharing са ключови за постигането на висока производителност и скорост.

Най-трудната част беше балансирането между производителност и правилна синхронизация. Първоначално имплементацията имаше race condition-и, които бяха трудни за откриване и отстраняване. Другото по трудно нещо беше да измисля и да намеря как да се оптимизира производителността. Реших да използвам batching, за да намаля броя на синхронизационните операции.

В следваща версия бих подобрил:
1. Добавяне на monitoring и logging система, която да показва производителността на системата, колко задачи се обработват на секунда, колко са задачите в очакване, колко са в процес на обработка, колко са готови и колко са грешни. Също целта е да не взима толкова много памет, колкото сега, дефакто да се изчистват стари логове.
2. Имплементация на по-добър shutdown механизъм, който да се справя с ситуации, в които потребителя иска да спре системата чрез заявка, която идва от отдалечена машина.
3. Добавяне на error recovery механизмъм, който да се справят с ситуации, в които системата се счупи и трябва да се възстанови.

Единственото, което ми остана неясно, е как бихме могли да скалираме системата върху множество отдалечени машини една от друга, запазвайки същата производителност.

## Как се стартира и спира системата

За да се стартира системата, трябва да изпълнят следните задачи:
 - make
 - ./run.sh

За да се спре системата, трябва в терминала да се прекъсне чрез CTRL+C.